# Software Requirements Specification (SRS)

## Project Title

AI Code CLI â€“ Openâ€‘Source Terminalâ€‘Based Coding Assistant (Claude/Geminiâ€‘like)

---

## 1. Introduction

### 1.1 Purpose

This document defines the complete **Software Requirements Specification (SRS)** for **AI Code CLI**, a terminalâ€‘based AI coding assistant inspired by **Claude Code CLI** and **Gemini CLI**, but built entirely using **JavaScript/TypeScript** and **free, openâ€‘source local LLMs**.

The SRS is intended for:

* Developers building or contributing to the project
* Openâ€‘source users and maintainers
* Academic or portfolio evaluation

---

### 1.2 Scope

AI Code CLI is a **crossâ€‘platform CLI tool** that:

* Runs fully **offline** using local LLMs
* Assists developers with **code generation, file creation, refactoring, and command execution**
* Provides an **interactive terminal UI** similar to Claude and Gemini CLIs
* Is distributed as a **global npm package**

No paid APIs or cloud services are required.

---

### 1.3 Definitions & Acronyms

| Term   | Meaning                                         |
| ------ | ----------------------------------------------- |
| LLM    | Large Language Model                            |
| CLI    | Command Line Interface                          |
| SRS    | Software Requirements Specification             |
| Agent  | AI system capable of planning + executing tasks |
| Ollama | Local LLM runtime                               |

---

## 2. Overall Description

### 2.1 Product Perspective

AI Code CLI is a **local AI agent** operating inside the terminal. It follows a **Plan â†’ Act â†’ Verify** loop similar to Claude Code.

Highâ€‘level flow:

```
User â†’ CLI â†’ AI Agent â†’ Tools (FS / Shell) â†’ Terminal UI
```

---

### 2.2 Target Users

* JavaScript / TypeScript developers
* Students with limited access to paid AI tools
* Openâ€‘source contributors
* Developers preferring terminal workflows

---

### 2.3 Operating Environment

| Component   | Requirement                        |
| ----------- | ---------------------------------- |
| OS          | Windows / macOS / Linux            |
| Runtime     | Node.js 18+                        |
| LLM Runtime | Ollama                             |
| Memory      | Minimum 8GB RAM (16GB recommended) |

---

## 3. System Architecture

### 3.1 Highâ€‘Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Terminal   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLI UI     â”‚  â† colors, panels, streaming text
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI Agent Coreâ”‚  â† planning & decision making
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Local LLM (Ollama)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tool Layer   â”‚ (FS / Shell)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 3.2 Technology Stack

| Layer     | Technology                             |
| --------- | -------------------------------------- |
| Language  | TypeScript                             |
| CLI       | commander                              |
| UI        | chalk, ora, readline                   |
| LLM       | Ollama (qwen2.5â€‘coder, deepseekâ€‘coder) |
| Shell     | execa                                  |
| Packaging | npm                                    |

---

## 4. Functional Requirements

### 4.1 CLI Interaction

**FRâ€‘1:** System shall accept natural language tasks via CLI arguments or interactive mode.

**FRâ€‘2:** System shall display streamed AI responses similar to Claude/Gemini.

**FRâ€‘3:** System shall show clear UI sections:

* User prompt
* AI reasoning
* Actions performed

---

### 4.2 AI Agent Behavior

**FRâ€‘4:** Agent shall break tasks into sequential steps.

**FRâ€‘5:** Agent shall only act via predefined tools:

* read_file
* write_file
* run_command
* done

**FRâ€‘6:** Agent shall loop until task completion.

---

### 4.3 File System Operations

**FRâ€‘7:** System shall create, modify, and read files within the project directory.

**FRâ€‘8:** System shall preview file changes before writing (future enhancement).

---

### 4.4 Command Execution

**FRâ€‘9:** System shall request user confirmation before executing any shell command.

**FRâ€‘10:** System shall block destructive commands (rm -rf, sudo, etc.).

---

## 5. Nonâ€‘Functional Requirements

### 5.1 Performance

* Average response latency: dependent on local model
* Must support streaming output

### 5.2 Security

* No external network calls except local Ollama
* Command allowâ€‘listing
* Projectâ€‘directory sandboxing

### 5.3 Usability

* Claudeâ€‘like conversational UI
* Clear prompts and confirmations
* Minimal configuration

---

## 6. Terminal UI Design (Claude / Geminiâ€‘like)

### UI Characteristics

* Colored role prefixes (User / AI / Tool)
* Animated spinner while AI thinks
* Streaming text output
* Command preview panel

Example:

```
â¯ ai-code "add login page"

ğŸ§  AI is thinking...

ğŸ¤– Plan:
- Create login page
- Add form

âš ï¸ Command to run:
npm install react-hook-form
Proceed? (y/n)
```

---

## 7. Ollama Setup (Initial Requirement)

### Step 1: Install Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### Step 2: Verify Installation

```bash
ollama --version
```

### Step 3: Download Coding Model

```bash
ollama pull qwen2.5-coder:7b
```

### Step 4: Test Model

```bash
ollama run qwen2.5-coder:7b
```

---

## 8. Stepâ€‘byâ€‘Step Development Guide (Ordered)

### Step 1: Initialize Project

* Create Node.js + TypeScript project
* Setup tsconfig

### Step 2: Create CLI Entry

* Setup commander
* Parse user input

### Step 3: Connect to Ollama

* Implement HTTP client
* Validate model availability

### Step 4: Design System Prompt

* Define JSONâ€‘only actions
* Restrict behavior

### Step 5: Build Agent Loop

* Parse AI output
* Execute tools

### Step 6: Implement Tools

* File system tool
* Shell execution tool

### Step 7: Build Terminal UI

* Streaming text
* Spinners
* Color formatting

### Step 8: Package for npm

* Add bin entry
* Compile TypeScript
* Publish

Each step depends strictly on the previous step.

---

## 9. Research & Inspiration

Based on analysis of:

* Claude Code CLI architecture
* Gemini CLI behavior
* Openâ€‘source tools: Aider, Cline, OpenCode

Common patterns observed:

* Agentâ€‘based planning
* Tool abstraction
* Strict safety rules
* Terminalâ€‘first UX

---

## 10. Future Enhancements

* Diff preview & undo
* Multiâ€‘model support
* Session memory
* Plugin system
* VS Code bridge

---

## 11. Conclusion

AI Code CLI provides a **costâ€‘free, privacyâ€‘friendly, and extensible alternative** to commercial AI coding CLIs. Using Ollama and openâ€‘source models ensures accessibility for developers worldwide.

---

**End of SRS**
